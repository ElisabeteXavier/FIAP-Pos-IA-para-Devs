{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7cc43fb",
   "metadata": {},
   "source": [
    "# CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceb1b224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "artigo_treino = pd.read_csv(\"../Aula 5 /treino.csv\")\n",
    "artigo_teste = pd.read_csv(\"../Aula 5 /teste.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f56d4099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U pip setuptools wheel\n",
    "# pip install -U spacy\n",
    "# python -m spacy download pt_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "996db166",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"pt_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f264c89c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texto = \"Adoro a cidade de Caldas novas\"\n",
    "\n",
    "doc = nlp(texto)\n",
    "\n",
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85bad3b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Adoro, Caldas novas)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a134fdc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[2].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fff72e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[1].is_alpha # é alphanumerico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f43511fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[1].is_stop #Verifica se é uma stopWord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02c51682",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tratar_textos(doc): #tirar_stopwords e numeros \n",
    "    tokens_validos = []\n",
    "    for token in doc:\n",
    "        e_valido = not token.is_stop and token.is_alpha\n",
    "        if e_valido:\n",
    "            tokens_validos.append(token.text)\n",
    "    if len(tokens_validos) > 2: #word2vec precisa no minimo uma frase com 3 palavras para o contexto\n",
    "        return \" \".join(tokens_validos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c16fa7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Adoro cidade Caldas'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texto = \"Adoro 255255 cidade de Caldas Novas!\"\n",
    "doc = nlp(texto)\n",
    "tratar_textos(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32b12115",
   "metadata": {},
   "outputs": [],
   "source": [
    "textos_para_tratamento = (titulos.lower() for titulos in artigo_treino.title)\n",
    "\n",
    "textos_tratados = [tratar_textos(doc) for doc in nlp.pipe(textos_para_tratamento,\n",
    "                                                         batch_size=100,\n",
    "                                                         n_process= -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01eeed50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titulo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>polêmica marine le pen abomina negacionistas h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>macron le pen turno frança revés siglas tradic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apesar larga vitória legislativas macron terá ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>governo antecipa balanço alckmin anuncia queda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>queda maio atividade econômica sobe junho bc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              titulo\n",
       "0  polêmica marine le pen abomina negacionistas h...\n",
       "1  macron le pen turno frança revés siglas tradic...\n",
       "2  apesar larga vitória legislativas macron terá ...\n",
       "3  governo antecipa balanço alckmin anuncia queda...\n",
       "4       queda maio atividade econômica sobe junho bc"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titulos_tratados = pd.DataFrame({\"titulo\": textos_tratados})\n",
    "titulos_tratados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "192c83b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "w2v_modelo = Word2Vec(sg = 0, # 0 para cbow e 1 skip gram \n",
    "               window= 2, # quantas palavras ele vai considerar uma antes e uma depois\n",
    "               vector_size=300, # tamanho do vetor  \n",
    "               min_count= 5, # eliminar as palavras  não recorrentes\n",
    "               alpha= 0.3, # taxa de aprendizgem\n",
    "               min_alpha= 0.007 # minimo de convergencia \n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4261335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90000\n",
      "84466\n"
     ]
    }
   ],
   "source": [
    "print(len(titulos_tratados))\n",
    "\n",
    "titulos_tratados = titulos_tratados.dropna().drop_duplicates()\n",
    "print(len(titulos_tratados))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a2b253d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_lista_tokens = [titulo.split(\" \") for titulo in titulos_tratados.titulo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94c097d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_modelo.build_vocab(lista_lista_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef09c422",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9a13291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_adapt_by_suffix',\n",
       " '_check_corpus_sanity',\n",
       " '_check_training_sanity',\n",
       " '_clear_post_train',\n",
       " '_do_train_epoch',\n",
       " '_do_train_job',\n",
       " '_get_next_alpha',\n",
       " '_get_thread_working_mem',\n",
       " '_job_producer',\n",
       " '_load_specials',\n",
       " '_log_epoch_end',\n",
       " '_log_epoch_progress',\n",
       " '_log_progress',\n",
       " '_log_train_end',\n",
       " '_raw_word_count',\n",
       " '_save_specials',\n",
       " '_scan_vocab',\n",
       " '_smart_save',\n",
       " '_train_epoch',\n",
       " '_train_epoch_corpusfile',\n",
       " '_worker_loop',\n",
       " '_worker_loop_corpusfile',\n",
       " 'add_lifecycle_event',\n",
       " 'add_null_word',\n",
       " 'alpha',\n",
       " 'batch_words',\n",
       " 'build_vocab',\n",
       " 'build_vocab_from_freq',\n",
       " 'cbow_mean',\n",
       " 'comment',\n",
       " 'compute_loss',\n",
       " 'corpus_count',\n",
       " 'corpus_total_words',\n",
       " 'create_binary_tree',\n",
       " 'cum_table',\n",
       " 'effective_min_count',\n",
       " 'epochs',\n",
       " 'estimate_memory',\n",
       " 'get_latest_training_loss',\n",
       " 'hashfxn',\n",
       " 'hs',\n",
       " 'init_sims',\n",
       " 'init_weights',\n",
       " 'layer1_size',\n",
       " 'lifecycle_events',\n",
       " 'load',\n",
       " 'make_cum_table',\n",
       " 'max_final_vocab',\n",
       " 'max_vocab_size',\n",
       " 'min_alpha',\n",
       " 'min_alpha_yet_reached',\n",
       " 'min_count',\n",
       " 'negative',\n",
       " 'ns_exponent',\n",
       " 'null_word',\n",
       " 'predict_output_word',\n",
       " 'prepare_vocab',\n",
       " 'prepare_weights',\n",
       " 'random',\n",
       " 'raw_vocab',\n",
       " 'reset_from',\n",
       " 'running_training_loss',\n",
       " 'sample',\n",
       " 'save',\n",
       " 'scan_vocab',\n",
       " 'score',\n",
       " 'seed',\n",
       " 'seeded_vector',\n",
       " 'sg',\n",
       " 'shrink_windows',\n",
       " 'sorted_vocab',\n",
       " 'syn1neg',\n",
       " 'total_train_time',\n",
       " 'train',\n",
       " 'train_count',\n",
       " 'update_weights',\n",
       " 'vector_size',\n",
       " 'window',\n",
       " 'workers',\n",
       " 'wv']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(w2v_modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e768c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84466"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_modelo.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e347b4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# iniciando a chamada callback\n",
    "class callback(CallbackAny2Vec):\n",
    "  def __init__(self):\n",
    "    self.epoch = 0\n",
    "\n",
    "  def on_epoch_end(self, model):\n",
    "    loss = model.get_latest_training_loss()\n",
    "    if self.epoch == 0:\n",
    "        print('Loss após a época {}: {}'.format(self.epoch, loss))\n",
    "    else:\n",
    "        print('Loss após a época {}: {}'.format(self.epoch, loss- self.loss_previous_step))\n",
    "    self.epoch += 1\n",
    "    self.loss_previous_step = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d26fcf81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss após a época 0: 462018.09375\n",
      "Loss após a época 1: 102737.78125\n",
      "Loss após a época 2: 44945.375\n",
      "Loss após a época 3: 24812.875\n",
      "Loss após a época 4: 18739.25\n",
      "Loss após a época 5: 14626.9375\n",
      "Loss após a época 6: 12961.9375\n",
      "Loss após a época 7: 10827.4375\n",
      "Loss após a época 8: 10010.25\n",
      "Loss após a época 9: 8979.6875\n",
      "Loss após a época 10: 8128.0625\n",
      "Loss após a época 11: 7148.75\n",
      "Loss após a época 12: 6934.1875\n",
      "Loss após a época 13: 6352.4375\n",
      "Loss após a época 14: 6035.125\n",
      "Loss após a época 15: 6130.375\n",
      "Loss após a época 16: 5532.625\n",
      "Loss após a época 17: 5215.0\n",
      "Loss após a época 18: 5034.875\n",
      "Loss após a época 19: 4855.9375\n",
      "Loss após a época 20: 5266.3125\n",
      "Loss após a época 21: 5051.25\n",
      "Loss após a época 22: 4508.9375\n",
      "Loss após a época 23: 4352.5\n",
      "Loss após a época 24: 4273.25\n",
      "Loss após a época 25: 4168.125\n",
      "Loss após a época 26: 4079.5\n",
      "Loss após a época 27: 3788.6875\n",
      "Loss após a época 28: 3770.8125\n",
      "Loss após a época 29: 3150.3125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14583837, 16207260)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_modelo.train(lista_lista_tokens,\n",
    "                 total_examples= w2v_modelo.corpus_count,\n",
    "                 epochs= 30,\n",
    "                 compute_loss= True,\n",
    "                 callbacks=[callback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5057d530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ajudado', 0.42669227719306946),\n",
       " ('desenvolve', 0.4007176160812378),\n",
       " ('cruzar', 0.38815540075302124),\n",
       " ('meme', 0.3784119784832001),\n",
       " ('preconceitos', 0.3763431906700134),\n",
       " ('françois', 0.37191373109817505),\n",
       " ('patentes', 0.3663933575153351),\n",
       " ('garcia', 0.36422330141067505),\n",
       " ('obstáculo', 0.36026448011398315),\n",
       " ('competição', 0.35763129591941833)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_modelo.wv.most_similar(\"google\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d22be8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5c9a4be",
   "metadata": {},
   "source": [
    "# Skip Gram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8284ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "w2v_modelo_sg = Word2Vec(sg = 1, # 0 para cbow e 1 skip gram \n",
    "               window= 5, # quantas palavras ele vai considerar uma antes e uma depois\n",
    "               vector_size=300, # tamanho do vetor  \n",
    "               min_count= 5, # eliminar as palavras  não recorrentes\n",
    "               alpha= 0.3, # taxa de aprendizgem\n",
    "               min_alpha= 0.007 # minimo de convergencia \n",
    "               )\n",
    "\n",
    "w2v_modelo_sg.build_vocab(lista_lista_tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "870d3bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss após a época 0: 589820.875\n",
      "Loss após a época 1: 55995.0625\n",
      "Loss após a época 2: 27323.125\n",
      "Loss após a época 3: 16991.75\n",
      "Loss após a época 4: 13608.5\n",
      "Loss após a época 5: 10883.125\n",
      "Loss após a época 6: 8703.375\n",
      "Loss após a época 7: 6927.6875\n",
      "Loss após a época 8: 6219.75\n",
      "Loss após a época 9: 5386.8125\n",
      "Loss após a época 10: 4905.0625\n",
      "Loss após a época 11: 3961.8125\n",
      "Loss após a época 12: 4095.5625\n",
      "Loss após a época 13: 3471.125\n",
      "Loss após a época 14: 2694.125\n",
      "Loss após a época 15: 2303.25\n",
      "Loss após a época 16: 2053.3125\n",
      "Loss após a época 17: 2081.3125\n",
      "Loss após a época 18: 1720.5\n",
      "Loss após a época 19: 1530.125\n",
      "Loss após a época 20: 1408.375\n",
      "Loss após a época 21: 1249.375\n",
      "Loss após a época 22: 1155.6875\n",
      "Loss após a época 23: 938.3125\n",
      "Loss após a época 24: 988.25\n",
      "Loss após a época 25: 738.25\n",
      "Loss após a época 26: 767.4375\n",
      "Loss após a época 27: 644.9375\n",
      "Loss após a época 28: 647.75\n",
      "Loss após a época 29: 490.1875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14584562, 16207260)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_modelo_sg.train(lista_lista_tokens,\n",
    "                 total_examples= w2v_modelo_sg.corpus_count,\n",
    "                 epochs= 30,\n",
    "                 compute_loss= True,\n",
    "                 callbacks=[callback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95fb8923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('esperam', 0.662084698677063),\n",
       " ('prejuízo', 0.640738308429718),\n",
       " ('corajosa', 0.63727205991745),\n",
       " ('piratas', 0.6354288458824158),\n",
       " ('aval', 0.6324977278709412),\n",
       " ('falas', 0.6290485858917236),\n",
       " ('iniciada', 0.6269177198410034),\n",
       " ('acabar', 0.6228968501091003),\n",
       " ('explode', 0.6205697655677795),\n",
       " ('jornalistas', 0.6179621815681458)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_modelo_sg.wv.most_similar(\"google\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a28bbae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6c9f49f",
   "metadata": {},
   "source": [
    "## Exportando modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53ce646d",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_modelo.wv.save_word2vec_format(\"./meu_modelo_cbow.txt\", binary= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "78caba39",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_modelo_sg.wv.save_word2vec_format(\"./meu_modelo_skip_gram.txt\", binary= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4706355",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "meu_modelo_cbow = KeyedVectors.load_word2vec_format(\"meu_modelo_cbow.txt\")\n",
    "meu_modelo_sg = KeyedVectors.load_word2vec_format(\"meu_modelo_skip_gram.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73682617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('femininos', 0.4863456189632416),\n",
       " ('legítima', 0.4783555865287781),\n",
       " ('aguinaldo', 0.4683089554309845),\n",
       " ('dizendo', 0.43608853220939636),\n",
       " ('ganhará', 0.4015822410583496),\n",
       " ('alongar', 0.40126514434814453),\n",
       " ('britney', 0.39318206906318665),\n",
       " ('bauza', 0.39195120334625244),\n",
       " ('farra', 0.3910873830318451),\n",
       " ('herdeiro', 0.3878246545791626)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meu_modelo_cbow.most_similar(\"ana\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b88fa43",
   "metadata": {},
   "source": [
    "# Classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d4076b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tokenizador(texto):\n",
    "#   tokens_validos = []\n",
    "#   doc = nlp(texto)\n",
    "#   for token in doc:\n",
    "#     e_valido = not token.is_stop and token.is_alpha\n",
    "#     if e_valido:\n",
    "#       tokens_validos.append(token.text.lower())\n",
    "\n",
    "#   return tokens_validos\n",
    "\n",
    "#COMENTEI ESSE TOKENIZADOR POR QUE ELE NÃO FUNCIONA BEM COM SPACY QUE USA PROCESSAMENTO EM LOTES\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "# def combinacao_de_vetores_por_soma(palavras_numeros,modelo):\n",
    "#   vetor_resultante = np.zeros(300)\n",
    "#   for pn in palavras_numeros:\n",
    "#     try: \n",
    "#       vetor_resultante =+ modelo.get_vector(pn)\n",
    "#     except KeyError:\n",
    "#       pass\n",
    "#   return vetor_resultante\n",
    "# def matriz_vetores(textos,modelo):\n",
    "#     x = len(textos)\n",
    "#     y = 300\n",
    "#     matriz = np.zeros((x,y))\n",
    "\n",
    "#     for i in range(x):\n",
    "#         palavras = tokenizador(textos.iloc[i])\n",
    "#         matriz[i]= combinacao_de_vetores_por_soma(palavras,modelo)\n",
    "#     return matriz\n",
    "# matriz_vetores_treino_cbow = matriz_vetores(artigo_treino.title,meu_modelo)\n",
    "# matriz_vetores_teste_cbow = matriz_vetores(artigo_teste.title,meu_modelo)\n",
    "\n",
    "# COMENTEI O RESTO DO CÓDIGO PQ += ESTA ERRADO NA FUNÇÃO  vetor_resultante =+ modelo.get_vector(pn)\n",
    "#  E A LOGICA NÃO IA FUNCIONAR FAZENDO O TOKENIZADOR DIFERENTE ENTÃO PRECISAVA DE MODIFICAÇÃO\n",
    "# O USO DO SPACY DEVERIA TER SIDO COMO NA FUNÇÃO NO COMEÇO DO NOTEBOOK TRATAR TEXTO\n",
    "\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\n",
    "    \"pt_core_news_sm\",\n",
    "    disable=[\"parser\", \"ner\", \"tagger\", \"textcat\"]\n",
    ")\n",
    "\n",
    "def tokenizador(doc):\n",
    "    return [\n",
    "        token.text.lower()\n",
    "        for token in doc\n",
    "        if token.is_alpha and not token.is_stop\n",
    "    ]\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def combinacao_de_vetores_por_soma(palavras, modelo):\n",
    "    vetor_resultante = np.zeros(300)\n",
    "    for pn in palavras:\n",
    "        try:\n",
    "            vetor_resultante += modelo.get_vector(pn)\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return vetor_resultante\n",
    "\n",
    "\n",
    "def matriz_vetores(docs, modelo):\n",
    "    x = len(docs)\n",
    "    y = 300\n",
    "    matriz = np.zeros((x, y))\n",
    "\n",
    "    for i, doc in enumerate(docs):\n",
    "        palavras = tokenizador(doc)\n",
    "        matriz[i] = combinacao_de_vetores_por_soma(palavras, modelo)\n",
    "\n",
    "    return matriz\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf95529b",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_treino = list(nlp.pipe(artigo_treino.title))\n",
    "docs_teste  = list(nlp.pipe(artigo_teste.title))\n",
    "\n",
    "matriz_vetores_treino_cbow = matriz_vetores(docs_treino, meu_modelo_cbow)\n",
    "matriz_vetores_teste_cbow  = matriz_vetores(docs_teste, meu_modelo_cbow)\n",
    "matriz_vetores_treino_sg = matriz_vetores(docs_treino, meu_modelo_sg)\n",
    "matriz_vetores_teste_sg  = matriz_vetores(docs_teste, meu_modelo_sg)\n",
    "\n",
    "# DA FORMA COMENTADA DEMOROU 20 MINUTOS PARA RODAR E AQUI 2MIN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d39444ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(matriz_vetores_teste_cbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8ec72931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90000, 300)\n",
      "(20513, 300)\n"
     ]
    }
   ],
   "source": [
    "print(matriz_vetores_treino_cbow.shape)\n",
    "print(matriz_vetores_teste_cbow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f63f7ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def classificador(x_treino,y_treino,x_teste, y_teste):\n",
    "    LR = LogisticRegression(max_iter= 800)\n",
    "    LR.fit(x_treino,y_treino)\n",
    "    categorias = LR.predict(x_teste)\n",
    "    CR = classification_report(y_teste,categorias)\n",
    "    print(CR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d8d7cf73",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m LR_cbow = \u001b[43mclassificador\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatriz_vetores_treino_cbow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m                        \u001b[49m\u001b[43martigo_treino\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcategory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mmatriz_vetores_teste_cbow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m                        \u001b[49m\u001b[43martigo_teste\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcategory\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mclassificador\u001b[39m\u001b[34m(x_treino, y_treino, x_teste, y_teste)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mclassificador\u001b[39m(x_treino,y_treino,x_teste, y_teste):\n\u001b[32m      5\u001b[39m     LR = LogisticRegression(max_iter= \u001b[32m800\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     \u001b[43mLR\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_treino\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_treino\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     categorias = LR.predict(x_teste)\n\u001b[32m      8\u001b[39m     CR = classification_report(y_teste,categorias)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git-repositórios/1python- pos-tech/venv/lib/python3.12/site-packages/sklearn/base.py:1336\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1329\u001b[39m     estimator._validate_params()\n\u001b[32m   1331\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1332\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1333\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1334\u001b[39m     )\n\u001b[32m   1335\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git-repositórios/1python- pos-tech/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1262\u001b[39m, in \u001b[36mLogisticRegression.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m   1258\u001b[39m \u001b[38;5;66;03m# TODO: enable multi-threading if benchmarks show a positive effect,\u001b[39;00m\n\u001b[32m   1259\u001b[39m \u001b[38;5;66;03m# see https://github.com/scikit-learn/scikit-learn/issues/32162\u001b[39;00m\n\u001b[32m   1260\u001b[39m n_threads = \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1262\u001b[39m coefs, _, n_iter = \u001b[43m_logistic_regression_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1263\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1264\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1265\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1266\u001b[39m \u001b[43m    \u001b[49m\u001b[43mCs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mC_\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1267\u001b[39m \u001b[43m    \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1268\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1269\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1270\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1271\u001b[39m \u001b[43m    \u001b[49m\u001b[43msolver\u001b[49m\u001b[43m=\u001b[49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1272\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1273\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1274\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1275\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1276\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcoef\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwarm_start_coef\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1277\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpenalty\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1278\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1279\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1280\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1281\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1283\u001b[39m \u001b[38;5;28mself\u001b[39m.n_iter_ = np.asarray(n_iter, dtype=np.int32)\n\u001b[32m   1285\u001b[39m \u001b[38;5;28mself\u001b[39m.coef_ = coefs[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git-repositórios/1python- pos-tech/venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:392\u001b[39m, in \u001b[36m_logistic_regression_path\u001b[39m\u001b[34m(X, y, classes, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[39m\n\u001b[32m    388\u001b[39m l2_reg_strength = \u001b[32m1.0\u001b[39m / (C * sw_sum)\n\u001b[32m    389\u001b[39m iprint = [-\u001b[32m1\u001b[39m, \u001b[32m50\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m100\u001b[39m, \u001b[32m101\u001b[39m][\n\u001b[32m    390\u001b[39m     np.searchsorted(np.array([\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m]), verbose)\n\u001b[32m    391\u001b[39m ]\n\u001b[32m--> \u001b[39m\u001b[32m392\u001b[39m opt_res = \u001b[43moptimize\u001b[49m\u001b[43m.\u001b[49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m    \u001b[49m\u001b[43mw0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mL-BFGS-B\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml2_reg_strength\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaxiter\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaxls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# default is 20\u001b[39;49;00m\n\u001b[32m    401\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgtol\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mftol\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m_get_additional_lbfgs_options_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43miprint\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miprint\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    406\u001b[39m n_iter_i = _check_optimize_result(\n\u001b[32m    407\u001b[39m     solver,\n\u001b[32m    408\u001b[39m     opt_res,\n\u001b[32m    409\u001b[39m     max_iter,\n\u001b[32m    410\u001b[39m     extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n\u001b[32m    411\u001b[39m )\n\u001b[32m    412\u001b[39m w0, loss = opt_res.x, opt_res.fun\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git-repositórios/1python- pos-tech/venv/lib/python3.12/site-packages/scipy/optimize/_minimize.py:784\u001b[39m, in \u001b[36mminimize\u001b[39m\u001b[34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[39m\n\u001b[32m    781\u001b[39m     res = _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[32m    782\u001b[39m                              **options)\n\u001b[32m    783\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m meth == \u001b[33m'\u001b[39m\u001b[33ml-bfgs-b\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m784\u001b[39m     res = \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    785\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    786\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m meth == \u001b[33m'\u001b[39m\u001b[33mtnc\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    787\u001b[39m     res = _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n\u001b[32m    788\u001b[39m                         **options)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git-repositórios/1python- pos-tech/venv/lib/python3.12/site-packages/scipy/optimize/_lbfgsb_py.py:469\u001b[39m, in \u001b[36m_minimize_lbfgsb\u001b[39m\u001b[34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, workers, **unknown_options)\u001b[39m\n\u001b[32m    461\u001b[39m _lbfgsb.setulb(m, x, low_bnd, upper_bnd, nbd, f, g, factr, pgtol, wa,\n\u001b[32m    462\u001b[39m                iwa, task, lsave, isave, dsave, maxls, ln_task)\n\u001b[32m    464\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m task[\u001b[32m0\u001b[39m] == \u001b[32m3\u001b[39m:\n\u001b[32m    465\u001b[39m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[32m    466\u001b[39m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[32m    467\u001b[39m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[32m    468\u001b[39m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m469\u001b[39m     f, g = \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m task[\u001b[32m0\u001b[39m] == \u001b[32m1\u001b[39m:\n\u001b[32m    471\u001b[39m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[32m    472\u001b[39m     n_iterations += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git-repositórios/1python- pos-tech/venv/lib/python3.12/site-packages/scipy/optimize/_differentiable_functions.py:412\u001b[39m, in \u001b[36mScalarFunction.fun_and_grad\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    410\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.array_equal(x, \u001b[38;5;28mself\u001b[39m.x):\n\u001b[32m    411\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_x(x)\n\u001b[32m--> \u001b[39m\u001b[32m412\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[38;5;28mself\u001b[39m._update_grad()\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.f, \u001b[38;5;28mself\u001b[39m.g\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git-repositórios/1python- pos-tech/venv/lib/python3.12/site-packages/scipy/optimize/_differentiable_functions.py:362\u001b[39m, in \u001b[36mScalarFunction._update_fun\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    360\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    361\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.f_updated:\n\u001b[32m--> \u001b[39m\u001b[32m362\u001b[39m         fx = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wrapped_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    363\u001b[39m         \u001b[38;5;28mself\u001b[39m._nfev += \u001b[32m1\u001b[39m\n\u001b[32m    364\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m fx < \u001b[38;5;28mself\u001b[39m._lowest_f:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git-repositórios/1python- pos-tech/venv/lib/python3.12/site-packages/scipy/_lib/_util.py:603\u001b[39m, in \u001b[36m_ScalarFunctionWrapper.__call__\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    600\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m    601\u001b[39m     \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[32m    602\u001b[39m     \u001b[38;5;66;03m# The user of this class might want `x` to remain unchanged.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m603\u001b[39m     fx = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    604\u001b[39m     \u001b[38;5;28mself\u001b[39m.nfev += \u001b[32m1\u001b[39m\n\u001b[32m    606\u001b[39m     \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git-repositórios/1python- pos-tech/venv/lib/python3.12/site-packages/scipy/optimize/_optimize.py:80\u001b[39m, in \u001b[36mMemoizeJac.__call__\u001b[39m\u001b[34m(self, x, *args)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, *args):\n\u001b[32m     79\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git-repositórios/1python- pos-tech/venv/lib/python3.12/site-packages/scipy/optimize/_optimize.py:74\u001b[39m, in \u001b[36mMemoizeJac._compute_if_needed\u001b[39m\u001b[34m(self, x, *args)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.all(x == \u001b[38;5;28mself\u001b[39m.x) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.jac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     73\u001b[39m     \u001b[38;5;28mself\u001b[39m.x = np.asarray(x).copy()\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m     fg = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28mself\u001b[39m.jac = fg[\u001b[32m1\u001b[39m]\n\u001b[32m     76\u001b[39m     \u001b[38;5;28mself\u001b[39m._value = fg[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git-repositórios/1python- pos-tech/venv/lib/python3.12/site-packages/sklearn/linear_model/_linear_loss.py:341\u001b[39m, in \u001b[36mLinearModelLoss.loss_gradient\u001b[39m\u001b[34m(self, coef, X, y, sample_weight, l2_reg_strength, n_threads, raw_prediction)\u001b[39m\n\u001b[32m    339\u001b[39m grad[:, :n_features] = grad_pointwise.T @ X + l2_reg_strength * weights\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fit_intercept:\n\u001b[32m--> \u001b[39m\u001b[32m341\u001b[39m     grad[:, -\u001b[32m1\u001b[39m] = \u001b[43mgrad_pointwise\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m coef.ndim == \u001b[32m1\u001b[39m:\n\u001b[32m    343\u001b[39m     grad = grad.ravel(order=\u001b[33m\"\u001b[39m\u001b[33mF\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git-repositórios/1python- pos-tech/venv/lib/python3.12/site-packages/numpy/_core/_methods.py:47\u001b[39m, in \u001b[36m_sum\u001b[39m\u001b[34m(a, axis, dtype, out, keepdims, initial, where)\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_amin\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     44\u001b[39m           initial=_NoValue, where=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m     45\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_minimum(a, axis, \u001b[38;5;28;01mNone\u001b[39;00m, out, keepdims, initial, where)\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_sum\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     48\u001b[39m          initial=_NoValue, where=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_sum(a, axis, dtype, out, keepdims, initial, where)\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_prod\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     52\u001b[39m           initial=_NoValue, where=\u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "LR_cbow = classificador(matriz_vetores_treino_cbow,\n",
    "                        artigo_treino.category,\n",
    "                        matriz_vetores_teste_cbow,\n",
    "                        artigo_teste.category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103ad8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_skip_gram = classificador(matriz_vetores_treino_sg,\n",
    "                        artigo_treino.category,\n",
    "                        matriz_vetores_teste_sg,\n",
    "                        artigo_teste.category)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
