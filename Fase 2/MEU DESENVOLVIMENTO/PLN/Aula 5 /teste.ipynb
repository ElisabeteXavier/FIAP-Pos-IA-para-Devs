{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "600bf8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "artigo_treino = pd.read_csv(\"./treino.csv\")\n",
    "artigo_teste = pd.read_csv(\"./teste.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92513c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'este': 1, 'produto': 3, 'muito': 2, 'bom': 0, 'ruim': 4}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "texto = [\n",
    "    \"Este produto é muito bom\",\n",
    "    \"Este produto é muito ruim\"\n",
    "]\n",
    "\n",
    "vetorizador = CountVectorizer()\n",
    "vetorizador.fit(texto)\n",
    "print(vetorizador.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5f6f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "525fff77dc3d4ead86073e700f44f301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embeddings.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7e1c1343d714f29984a09a7c205e10f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(929606, 300)\n"
     ]
    }
   ],
   "source": [
    "# from huggingface_hub import hf_hub_download\n",
    "# from safetensors.numpy import load_file\n",
    "\n",
    "# path = hf_hub_download(repo_id=\"nilc-nlp/word2vec-cbow-300d\",\n",
    "#                        filename=\"embeddings.safetensors\")\n",
    "\n",
    "# data = load_file(path)\n",
    "# vectors = data[\"embeddings\"]\n",
    "\n",
    "# vocab_path = hf_hub_download(repo_id=\"nilc-nlp/word2vec-cbow-300d\",\n",
    "#                              filename=\"vocab.txt\")\n",
    "# with open(vocab_path) as f:\n",
    "#     vocab = [w.strip() for w in f]\n",
    "\n",
    "# print(vectors.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de6bc2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "929606 (929606, 300)\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "from safetensors.numpy import load_file\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# embeddings\n",
    "path = hf_hub_download(\n",
    "    repo_id=\"nilc-nlp/word2vec-cbow-300d\",\n",
    "    filename=\"embeddings.safetensors\"\n",
    ")\n",
    "data = load_file(path)\n",
    "vectors = data[\"embeddings\"]\n",
    "\n",
    "# vocabulário\n",
    "vocab_path = hf_hub_download(\n",
    "    repo_id=\"nilc-nlp/word2vec-cbow-300d\",\n",
    "    filename=\"vocab.txt\"\n",
    ")\n",
    "with open(vocab_path, encoding=\"utf-8\") as f:\n",
    "    vocab = [w.strip() for w in f]\n",
    "\n",
    "# checagem de sanidade\n",
    "print(len(vocab), vectors.shape)\n",
    "\n",
    "# Word2Vec no gensim\n",
    "modelo = KeyedVectors(vector_size=vectors.shape[1])\n",
    "modelo.add_vectors(vocab, vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9e6f82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "modelo = KeyedVectors(vector_size=300)\n",
    "modelo.add_vectors(vocab, vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23fd20d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['embeddings'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b9e6d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('afeto', 0.7056611180305481),\n",
       " ('tormento', 0.6202821135520935),\n",
       " ('desamor', 0.6199557781219482),\n",
       " ('ciúme', 0.6167261600494385),\n",
       " ('arrependimento', 0.6010848879814148),\n",
       " ('encanto', 0.5992918014526367),\n",
       " ('instincto', 0.5957212448120117),\n",
       " ('ódio', 0.580238401889801),\n",
       " ('infortúnio', 0.5744850039482117),\n",
       " ('egoísmo', 0.5689378380775452)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.most_similar(\"amor\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda3fa90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
